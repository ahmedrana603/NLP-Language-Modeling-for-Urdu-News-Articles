# ğŸ“° Urdu News Language Modeling & Text Generation System

An end-to-end Natural Language Processing (NLP) pipeline for Urdu news articles built from scratch using real-world data from BBC Urdu.

This project scrapes, preprocesses, models, and generates BBC-style Urdu news articles using statistical language models without relying on pretrained NLP libraries.

---

## ğŸš€ Project Overview

The system performs:

- Scraping 200â€“300 real Urdu news articles  
- Unicode normalization and text cleaning  
- Custom Urdu linguistic preprocessing  
- Statistical language model training (Unigram, Bigram, Trigram)  
- BBC-style Urdu article generation  
- Perplexity-based evaluation  

All components â€” tokenization, stemming, lemmatization, smoothing, and backoff â€” are implemented from scratch.

---

## ğŸ“¥ Data Collection

Source: https://www.bbc.com/urdu  
Articles Scraped: 200â€“300 complete news articles  
Each article is assigned a unique identifier.

---

## ğŸ§¹ Text Preprocessing Pipeline

Urdu presents unique preprocessing challenges due to Unicode variation, optional diacritics, and mixed scripts. The following cleaning steps are applied:

### Diacritics Removal (optional Urdu diacritics to reduce lexical sparsity)

### Noise Removal (URLs, Emojis, Navigation elements, Web artifacts)

### Non-Urdu Text Filtering (English words, Roman Urdu, Mixed-script tokens)

### Sentence Segmentation (Urdu punctuation: Û” ØŸ !)

### Whitespace Normalization (standardized spacing and formatting inconsistencies)

---

## ğŸ”  Custom Linguistic Processing

All linguistic tools are implemented manually.

### Urdu Tokenization (word boundary detection, punctuation handling, postposition handling, numbers replaced with `<NUM>`)

### Urdu Stemming (rule-based suffix stripping to reduce words to root forms)

### Urdu Lemmatization (plural normalization, gender normalization, rule-based mapping)

---

## ğŸ§  Language Models

The following statistical language models are implemented:

- Unigram Model (used for evaluation and backoff)  
- Bigram Model  
- Trigram Model with Backoff  

---

## ğŸ” Backoff Strategy

Hierarchical backoff is applied:

Trigram â†’ Bigram â†’ Unigram

If a trigram context is unseen, the system falls back to bigram probability.  
If the bigram is also unseen, it falls back to unigram probability.

---

## ğŸ“Š Smoothing Techniques

To handle unseen n-grams and prevent zero probabilities:

### Laplace (Add-One) Smoothing

### Add-k Smoothing

These techniques ensure stable probability estimation and improved generalization.

---

## ğŸ“° Article Generation System

The generation module supports:

- Language model selection (Bigram / Trigram)  
- Custom seed prompt input (5â€“8 Urdu words)  
- Automatic article generation  
- Right-to-Left (RTL) formatted output  
- Length and sentence constraints  

---

## ğŸ“ Generation Constraints

- Minimum length: 200 words  
- Target length: 200â€“250 words  
- Maximum length: 300 words  
- At least 5 sentences required  
- Forced termination if EOS is not generated  

The generated text is designed to be original, formal, structured, coherent, and readable.

---

## ğŸ“ˆ Evaluation

Generated articles are evaluated using:

- Fluency  
- Grammatical correctness  
- Coherence  
- Readability  
- Perplexity score  

Comparative analysis includes:

- Raw vs. Cleaned preprocessing pipelines  
- Bigram vs. Trigram with Backoff  

---

## ğŸ–¥ Interface

- Console-based article generation interface  
- Model selection  
- Seed prompt validation  
- RTL Urdu display formatting  

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ notebook.ipynb  
â”œâ”€â”€ Metadata.json  
â”œâ”€â”€ raw.txt  
â”œâ”€â”€ cleaned.txt  
â”œâ”€â”€ README.md  

---

## âš™ï¸ How to Run

1. Open the Jupyter Notebook  
2. Run the preprocessing pipeline  
3. Train the language models  
4. Launch the article generation interface  
5. Provide a valid 5â€“8 word Urdu seed prompt  

---

## ğŸ¯ Key Features

- Fully custom Urdu NLP pipeline  
- No pretrained NLP libraries used  
- Statistical modeling from scratch  
- Backoff language modeling  
- Perplexity-based evaluation  
- RTL-aware Urdu text rendering  


---

## ğŸ“œ License

This project is developed for educational and research purposes only.

BBC content is used strictly for non-commercial academic experimentation.
